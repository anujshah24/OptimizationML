{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network Class for implementing neural networks for different loss and optimization functions.\n",
    "    \n",
    "    Attributes:\n",
    "        input_size: An integer indicating number of input features.\n",
    "        output_size: An integer indicating size of output.\n",
    "        hidden_layer_size: An integer indicating size of hidden layer.\n",
    "        \n",
    "        w1: A vector (input_size X hidden_layers_sizes[0]) of floats required for training the neural network.\n",
    "        wn: A vector (hidden_layers_sizes[-1] X output_size) for weights of final layer.\n",
    "        \n",
    "        activations: An array of strings indicating the activation functions for every layer.\n",
    "        loss: A string indicating the loss function for the neural network.\n",
    "        optimizer: A string indicating the optimization algorithm to be used to train the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_layer_size, activations, loss, optimizer):\n",
    "        \"\"\"\n",
    "        Initializes Neural Network class attributes.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of features of the input.\n",
    "            output_size (int): Dimension of output.\n",
    "            hidden_layer_size (int): Number of neurons in the input layer.\n",
    "            activations (list): List of strings giving the activations for each layer.\n",
    "            loss (str): Loss function for the model.\n",
    "            optimizer (str): Optimization algorithm for the model.\n",
    "        \"\"\"\n",
    "        super(NeuralNetwork, self)\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.w1 = torch.randn(self.input_size, self.hidden_layer_size, dtype=torch.double)\n",
    "        self.wn = torch.randn(self.hidden_layer_size, self.output_size, dtype=torch.double)\n",
    "    \n",
    "        self.activations = activations\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    \n",
    "    def forward(self, X, w1=None, wn=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network.\n",
    "        \n",
    "        Args:\n",
    "            X (tensor): Input for the model. \n",
    "            w1 (tensor): Weights to be used for the first layer. (Optional Argument)\n",
    "            wn (tensor): Weights to be used for the final layer. (Optional Argument)\n",
    "            \n",
    "        Returns:\n",
    "            z (list): List of outputs from linear function at each layer.\n",
    "            a (list): List of activation outputs from each layer.\n",
    "        \"\"\"\n",
    "        if w1 is None:\n",
    "            w1 = self.w1\n",
    "        if wn is None:\n",
    "            wn = self.wn\n",
    "        z = []\n",
    "        a = []\n",
    "        z.append(torch.matmul(X, w1))\n",
    "        a.append(self.evaluateActivation(self.activations[0])(z[-1]))\n",
    "        z.append(torch.matmul(a[-1], wn))\n",
    "        a.append(self.evaluateActivation(self.activations[1])(z[-1]))\n",
    "        return z, a\n",
    "    \n",
    "    \n",
    "    def backward(self, X, y, z, a, wn=None):\n",
    "        \"\"\"\n",
    "        Backward Pass of the model.\n",
    "        \n",
    "        Args:\n",
    "            X (Tensor): Input Data\n",
    "            y (Tensor): Output Data\n",
    "            z (list): List of outputs from linear layers.\n",
    "            a (list): List of actiation outputs.\n",
    "            wn (Tensor): Weights from final layer. (Optional Argument)\n",
    "        \"\"\"\n",
    "        if wn is None:\n",
    "            wn = self.wn\n",
    "        dW = []\n",
    "        dL_da_n = self.evaluateLossDerivative()(a[-1], y)\n",
    "        da_n_dz_n = self.evaluateActivationDerivative(self.activations[1])(z[-1])\n",
    "        dz_n_dWn = a[0]\n",
    "        dL_dWn = torch.matmul(dz_n_dWn.T, (dL_da_n * da_n_dz_n))\n",
    "        \n",
    "        dz_n_da_1 = wn\n",
    "        da_1_dz_1 = self.evaluateActivationDerivative(self.activations[0])(z[0])\n",
    "        dz_1_dW1 = X\n",
    "        dL_dW1 = torch.matmul(dz_1_dW1.T, (torch.matmul(dL_da_n * da_n_dz_n, dz_n_da_1.T)*da_1_dz_1))\n",
    "        dW.append(dL_dW1)\n",
    "        dW.append(dL_dWn)\n",
    "        return dW\n",
    "    \n",
    "    \n",
    "    def train(self, X, y, batch_size=100, iterations=500, alpha=1e-05, momentum_param=0, nesterov=False, decay_rate=0.999, beta1=0.9, beta2=0.999):\n",
    "        \"\"\"\n",
    "        Function to train the neural network.\n",
    "        \"\"\"\n",
    "        funVals = []\n",
    "        ypred = None\n",
    "        if self.optimizer == 'SGD':\n",
    "            if momentum_param != 0:\n",
    "                if nesterov:\n",
    "                    funVals ,ypred = self.SGD(X, y, batch_size, iterations, alpha, momentum_param, True)\n",
    "                else:\n",
    "                    funVals, ypred = self.SGD(X, y, batch_size, iterations, alpha, momentum_param)\n",
    "            else:\n",
    "                funVals, ypred = self.SGD(X, y, batch_size, iterations, alpha)\n",
    "        elif self.optimizer == 'Adagrad':\n",
    "            funVals, ypred = self.Adagrad(X, y, batch_size, iterations, alpha)\n",
    "        elif self.optimizer == 'RMSProp':\n",
    "            funVals, ypred = self.RMSProp(X, y, batch_size, iterations, alpha, decay_rate)\n",
    "        elif self.optimizer == 'Adam':\n",
    "            funVals, ypred = self.Adam(X, y, batch_size, iterations, alpha, beta1, beta2)\n",
    "        return funVals, ypred\n",
    "    \n",
    "    \n",
    "    def SGD(self, X, y, batch_size=100, iterations=500, alpha=1e-05, momentum_param=0, nesterov=False):\n",
    "        \"\"\"\n",
    "        Gradient Descent Algorithm\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        funVals = []\n",
    "        ypred = []\n",
    "        v1 = torch.zeros(self.w1.shape, dtype=torch.double)\n",
    "        vn = torch.zeros(self.wn.shape, dtype=torch.double)\n",
    "        n_iter = 0\n",
    "        flag = True\n",
    "        while flag:\n",
    "            for i in range(m//batch_size):\n",
    "                n_iter += 1\n",
    "                if nesterov:\n",
    "                    z, a = self.forward(X[i:i+batch_size], self.w1+momentum_param*v1, self.wn+momentum_param*vn)\n",
    "                    dW = self.backward(X[i:i+batch_size], y[i:i+batch_size], z, a, self.wn+momentum_param*vn)\n",
    "                else:\n",
    "                    z, a = self.forward(X[i:i+batch_size])\n",
    "                    dW = self.backward(X[i:i+batch_size], y[i:i+batch_size], z, a)\n",
    "                v1 = momentum_param * v1 - alpha * dW[0]\n",
    "                vn = momentum_param * vn - alpha * dW[1]\n",
    "                self.w1 = self.w1 + v1\n",
    "                self.wn = self.wn + vn\n",
    "                if n_iter>iterations:\n",
    "                    flag = False\n",
    "                    break\n",
    "                if n_iter%batch_size == 0:\n",
    "                    ypred = self.predict(X)\n",
    "                    funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "                    print(n_iter, funVals[-1])\n",
    "            W = torch.cat([self.w1.flatten().reshape(-1, 1), self.wn.reshape(-1,1)])\n",
    "            optCond = torch.matmul(W.T, W)\n",
    "            if optCond < 1e-2 or n_iter>iterations:\n",
    "                break\n",
    "            ypred = self.predict(X)\n",
    "            funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "#             print(n_iter, funVals[-1])\n",
    "        ypred = self.predict(X)\n",
    "        if self.loss == 'CELoss':\n",
    "            ypred = self.softmax(ypred)\n",
    "        return funVals, ypred\n",
    "    \n",
    "    \n",
    "    def Adagrad(self, X, y, batch_size=100, iterations=500, alpha=1e-5):\n",
    "        \"\"\"\n",
    "        AdaGrad Optimizer\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        funVals = []\n",
    "        ypred = []\n",
    "        n_iter = 0\n",
    "        flag = True\n",
    "        smoothing_param = 1e-8\n",
    "        cache1 = torch.zeros(self.w1.shape, dtype=torch.double)\n",
    "        cache2 = torch.zeros(self.wn.shape, dtype=torch.double)\n",
    "        while flag:\n",
    "            for i in range(m//batch_size):\n",
    "                n_iter += 1\n",
    "                z, a = self.forward(X[i:i+batch_size])\n",
    "                dW = self.backward(X[i:i+batch_size], y[i:i+batch_size], z, a)\n",
    "                cache1 += dW[0]**2\n",
    "                cache2 += dW[1]**2\n",
    "                self.w1 += -(alpha/(torch.sqrt(cache1)+smoothing_param)) * dW[0]\n",
    "                self.wn += -(alpha/(torch.sqrt(cache2)+smoothing_param)) * dW[1]\n",
    "                if n_iter>iterations:\n",
    "                    flag = False\n",
    "                    break\n",
    "                if n_iter%batch_size == 0:\n",
    "                    ypred = self.predict(X)\n",
    "                    funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "                    print(n_iter, funVals[-1])\n",
    "            W = torch.cat([self.w1.flatten().reshape(-1, 1), self.wn.reshape(-1,1)])\n",
    "            optCond = torch.matmul(W.T, W)\n",
    "            if optCond < 1e-2 or n_iter>iterations:\n",
    "                break\n",
    "            ypred = self.predict(X)\n",
    "            funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "#             print(n_iter, funVals[-1])\n",
    "        ypred = self.predict(X)\n",
    "        if self.loss == 'CELoss':\n",
    "            ypred = self.softmax(ypred)\n",
    "        return funVals, ypred\n",
    "    \n",
    "    \n",
    "    def RMSProp(self, X, y, batch_size=100, iterations=500, alpha=1e-04, decay_rate=0.999):\n",
    "        \"\"\"\n",
    "        RMSProp Optimizer.\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        funVals = []\n",
    "        ypred = []\n",
    "        n_iter = 0\n",
    "        flag = True\n",
    "        smoothing_param = 1e-8\n",
    "        cache1 = torch.zeros(self.w1.shape, dtype=torch.double)\n",
    "        cache2 = torch.zeros(self.wn.shape, dtype=torch.double)\n",
    "        while flag:\n",
    "            for i in range(m//batch_size):\n",
    "                n_iter += 1\n",
    "                z, a = self.forward(X[i:i+batch_size])\n",
    "                dW = self.backward(X[i:i+batch_size], y[i:i+batch_size], z, a)\n",
    "                cache1 = decay_rate*cache1 + (1 - decay_rate) * dW[0]**2\n",
    "                cache2 += dW[1]**2\n",
    "                self.w1 += -(alpha/(torch.sqrt(cache1+smoothing_param))) * dW[0]\n",
    "                self.wn += -(alpha/(torch.sqrt(cache2+smoothing_param))) * dW[1]\n",
    "                if n_iter>iterations:\n",
    "                    flag = False\n",
    "                    break\n",
    "                if n_iter%batch_size == 0:\n",
    "                    ypred = self.predict(X)\n",
    "                    funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "#                     print(n_iter, funVals[-1])\n",
    "            W = torch.cat([self.w1.flatten().reshape(-1, 1), self.wn.reshape(-1,1)])\n",
    "            optCond = torch.matmul(W.T, W)\n",
    "            if optCond < 1e-2 or n_iter>iterations:\n",
    "                break\n",
    "            ypred = self.predict(X)\n",
    "            funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "#             print(n_iter, funVals[-1])\n",
    "        ypred = self.predict(X)\n",
    "        if self.loss == 'CELoss':\n",
    "            ypred = self.softmax(ypred)\n",
    "        return funVals, ypred\n",
    "    \n",
    "    \n",
    "    def Adam(self, X, y, batch_size=100, iterations=500, alpha=1e-04, beta1=0.9, beta2=0.999):\n",
    "        \"\"\"\n",
    "        Adam Optimizer\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        funVals = []\n",
    "        ypred = []\n",
    "        n_iter = 0\n",
    "        flag = True\n",
    "        smoothing_param = 1e-8\n",
    "        m1 = torch.zeros(self.w1.shape, dtype=torch.double)\n",
    "        m2 = torch.zeros(self.wn.shape, dtype=torch.double)\n",
    "        v1 = torch.zeros(self.w1.shape, dtype=torch.double)\n",
    "        v2 = torch.zeros(self.wn.shape, dtype=torch.double)\n",
    "        while flag:\n",
    "            for i in range(m//batch_size):\n",
    "                n_iter += 1\n",
    "                z, a = self.forward(X[i:i+batch_size])\n",
    "                dW = self.backward(X[i:i+batch_size], y[i:i+batch_size], z, a)\n",
    "                m1 = beta1 * m1 + (1-beta1) * dW[0]\n",
    "                v1 = beta2 * v1 + (1-beta2) * dW[0]**2\n",
    "                m2 = beta1 * m2 + (1-beta1) * dW[1]\n",
    "                v2 = beta2 * v2 + (1-beta2) * dW[1]**2\n",
    "                self.w1 += -alpha*(m1/(1-beta1**n_iter))/(torch.sqrt((v1)/(1-beta2**n_iter)) + smoothing_param)\n",
    "                self.wn += -alpha*(m2/(1-beta1**n_iter))/(torch.sqrt((v2)/(1-beta2**n_iter)) + smoothing_param)\n",
    "                if n_iter>iterations:\n",
    "                    flag = False\n",
    "                    break\n",
    "                if n_iter%batch_size == 0:\n",
    "                    ypred = self.predict(X)\n",
    "                    funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "                    print(n_iter, funVals[-1])\n",
    "            W = torch.cat([self.w1.flatten().reshape(-1, 1), self.wn.reshape(-1,1)])\n",
    "            optCond = torch.matmul(W.T, W)\n",
    "            if optCond < 1e-2 or n_iter>iterations:\n",
    "                break\n",
    "            ypred = self.predict(X)\n",
    "            funVals.append((self.evaluateLoss()(ypred, y)).item())\n",
    "#             print(n_iter, funVals[-1])\n",
    "        ypred = self.predict(X)\n",
    "        if self.loss == 'CELoss':\n",
    "            ypred = self.softmax(ypred)\n",
    "        return funVals, ypred\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict function\n",
    "        \"\"\"\n",
    "        _, a = self.forward(X)\n",
    "        return a[-1]\n",
    "    \n",
    "    \n",
    "    def reset_weights(self):\n",
    "        \"\"\"\n",
    "        Reset Weights\n",
    "        \"\"\"\n",
    "        self.w1 = torch.randn(self.input_size, self.hidden_layer_size, dtype=torch.double)\n",
    "        self.wn = torch.randn(self.hidden_layer_size, self.output_size, dtype=torch.double)\n",
    "    \n",
    "    \n",
    "    def evaluateActivation(self, activation):\n",
    "        \"\"\"\n",
    "        Activation function\n",
    "        \"\"\"\n",
    "        if activation == 'sigmoid' :\n",
    "            return lambda z : torch.exp(z)/(1 + torch.exp(z))\n",
    "        elif activation == 'relu':\n",
    "            def relu(z):\n",
    "                z1 = torch.clone(z)\n",
    "                return z1.clamp(min=0)\n",
    "            return relu\n",
    "        elif activation == 'tanh':\n",
    "            return lambda z : (2/(1+torch.exp(-2*z))) - 1\n",
    "        return lambda z : z\n",
    "    \n",
    "    \n",
    "    def evaluateActivationDerivative(self, activation):\n",
    "        \"\"\"\n",
    "        Derivative of Activation Function\n",
    "        \"\"\"\n",
    "        if activation == 'sigmoid':\n",
    "            sigmoid = lambda z : torch.exp(z)/(1 + torch.exp(z))\n",
    "            return lambda z : sigmoid(z) * (1 - sigmoid(z))\n",
    "        elif activation == 'relu':\n",
    "            def relu_derivative(z):\n",
    "                z1 = torch.clone(z)\n",
    "                z1[z>=0] = 1\n",
    "                z1[z<0] = 0\n",
    "                return z1\n",
    "            return relu_derivative\n",
    "        elif activation == 'tanh':\n",
    "            tanh = lambda z : (2/(1+torch.exp(-2*z))) - 1\n",
    "            return lambda z : 1 - tanh(z)**2\n",
    "        return lambda z : 1\n",
    "    \n",
    "    \n",
    "    def evaluateLoss(self):\n",
    "        \"\"\"\n",
    "        Loss Function\n",
    "        \"\"\"\n",
    "        if self.loss == 'MSE':\n",
    "            return lambda ypred, y : torch.matmul((ypred - y).T, (ypred - y))/(2*len(y))\n",
    "        elif self.loss == 'BCELoss':\n",
    "            return lambda ypred, y : (-1/len(y))*(torch.matmul(y.T, torch.log(ypred)) + torch.matmul((1-y).T, torch.log(1-ypred)))\n",
    "        elif self.loss == \"CELoss\":\n",
    "            def crossEntropyLoss(ypred, y):\n",
    "                m = y.shape[0]\n",
    "                prob = self.softmax(ypred)\n",
    "                log_likelihood = -torch.log(prob[range(m), y.long()])\n",
    "                loss = torch.sum(log_likelihood)\n",
    "                return loss/m\n",
    "            return crossEntropyLoss\n",
    "        return lambda x : 1\n",
    "    \n",
    "    \n",
    "    def evaluateLossDerivative(self):\n",
    "        \"\"\"\n",
    "        Loss function Derivative\n",
    "        \"\"\"\n",
    "        if self.loss == 'MSE':\n",
    "            return lambda ypred, y: (ypred - y)/len(y)\n",
    "        elif self.loss == 'BCELoss':\n",
    "            return lambda ypred, y: (-1/len(y)) * ((y/ypred) - ((1-y)/(1-ypred)))\n",
    "        elif self.loss == 'CELoss':\n",
    "            def crossEntropyLossGradient(ypred, y):\n",
    "                m = y.shape[0]\n",
    "                grad = self.softmax(ypred)\n",
    "                grad[range(m), y.long()] -= 1\n",
    "                return grad/m\n",
    "            return crossEntropyLossGradient\n",
    "        return lambda x : 1\n",
    "    \n",
    "    \n",
    "    def softmax(self, z):\n",
    "        exps = torch.exp(z - torch.max(z, dim=0).values)\n",
    "        return exps/torch.sum(exps, dim=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.rand(312, 20, dtype=torch.double)\n",
    "# # y = torch.randint(0, 2,(1000, 1)).double()\n",
    "# # y = torch.randn(312, 1, dtype=torch.double)\n",
    "# y = torch.randint(0,3,(312, 1)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork(X.shape[1], 3, 32, ['tanh', 'linear'], 'CELoss', 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funVals, ypred = model.train(X, y, batch_size=100, iterations=1500, alpha=1e-03, momentum_param=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((torch.sum(ypred.argmax(dim=1).reshape(-1,1) == y.long()).float()*100.0)/(y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# # def plotLoss(funVals, filePath, title):\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot([i for i in range(1, len(funVals)+1)], funVals)\n",
    "# plt.xlabel(\"Number of Iterations\")\n",
    "# plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plotLoss(funVals, filePath, title, plot=False):\n",
    "    import matplotlib.pyplot as plt\n",
    "#     plt.xkcd()\n",
    "    plt.plot([i for i in range(1, len(funVals)+1)], funVals)\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(\"./dataset/\"+filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAutoMPGDataset():\n",
    "    import pandas as pd\n",
    "    auto_mpg_dataset = pd.read_csv(\"./dataset/auto-mpg/auto-mpg.data\", header=-1, comment='\\t', skipinitialspace=True, na_values='?', sep=' ')\n",
    "    auto_mpg_dataset = auto_mpg_dataset.dropna()\n",
    "    origin = auto_mpg_dataset.pop(7)\n",
    "    auto_mpg_dataset[7] = (origin==1)*1.0\n",
    "    auto_mpg_dataset[8] = (origin==2)*1.0\n",
    "    auto_mpg_dataset[9] = (origin==3)*1.0\n",
    "    auto_dataset = torch.tensor(auto_mpg_dataset.values, dtype=torch.double)\n",
    "    return auto_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_dataset = loadAutoMPGDataset()\n",
    "auto_dataset = auto_dataset[torch.randperm(auto_dataset.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = auto_dataset[:int(0.8 * auto_dataset.shape[0])]\n",
    "test = auto_dataset[int(0.8 * auto_dataset.shape[0]):]\n",
    "\n",
    "Xtrain = train[:, 1:]\n",
    "Xtrain = (Xtrain - Xtrain.mean(dim=0))/Xtrain.std(dim=0)\n",
    "ytrain = train[:, 0].reshape(-1, 1)\n",
    "\n",
    "Xtest = test[:, 1:]\n",
    "Xtest = (Xtest - Xtest.mean(dim=0))/Xtest.std(dim=0)\n",
    "ytest = test[:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_mpg_model = NeuralNetwork(Xtrain.shape[1], ytrain.shape[1], 64, ['relu', 'relu'], 'MSE', 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_mpg_model.reset_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 92.35154064724551\n",
      "200 60.37551350628857\n",
      "300 16.38864548239426\n",
      "400 11.228666537004942\n",
      "500 8.6939875210588\n",
      "600 7.326550375680231\n",
      "700 6.5283281835459315\n",
      "800 5.983569662423891\n",
      "900 5.56736374660477\n",
      "1000 5.232870761350045\n"
     ]
    }
   ],
   "source": [
    "funVals, ypred = auto_mpg_model.train(Xtrain, ytrain, batch_size=100, iterations=1000, alpha=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLoss(funVals, filePath=\"auto-mpg/results/Adam.png\", title=\"Adam\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD sigmoid MSE\n",
      "100 276.6078519099577\n",
      "200 276.5993151088307\n",
      "300 276.59495619007055\n",
      "400 276.59229524456094\n",
      "500 276.59049765713576\n",
      "600 276.58920016024365\n",
      "700 276.5882187150613\n",
      "800 276.58744993164464\n",
      "900 276.58683118542774\n",
      "1000 276.58632229909\n",
      "SGD relu MSE\n",
      "100 4.709610665900517\n",
      "200 4.017769087190342\n",
      "300 3.884643936920674\n",
      "400 3.8904401320838904\n",
      "500 3.9388946165526053\n",
      "600 3.981789256017858\n",
      "700 4.02689951765446\n",
      "800 4.059245655406223\n",
      "900 4.09459984940614\n",
      "1000 4.127573319223757\n",
      "SGD tanh MSE\n",
      "100 281.4035491347004\n",
      "200 277.9518028062116\n",
      "300 277.7854190302308\n",
      "400 277.7330647965763\n",
      "500 277.69928018498075\n",
      "600 277.67463953748353\n",
      "700 277.6553587822695\n",
      "800 277.6395817978316\n",
      "900 277.62626576703013\n",
      "1000 277.6147692164138\n",
      "SGDNesterov sigmoid MSE\n",
      "SGDNesterov relu MSE\n",
      "SGDNesterov tanh MSE\n",
      "Adagrad sigmoid MSE\n",
      "100 287.1718453721118\n",
      "200 285.7716594968718\n",
      "300 284.91996535275905\n",
      "400 284.3298394941643\n",
      "500 283.8721910626101\n",
      "600 283.4873859214489\n",
      "700 283.1453137417808\n",
      "800 282.8295728916346\n",
      "900 282.5308914119167\n",
      "1000 282.24401168350477\n",
      "Adagrad relu MSE\n",
      "100 172.75633128610627\n",
      "200 163.3067345053659\n",
      "300 156.9330814716403\n",
      "400 152.12573732733193\n",
      "500 148.11684618726989\n",
      "600 144.81372987835698\n",
      "700 141.93500453192985\n",
      "800 139.4176054861897\n",
      "900 137.22721626354695\n",
      "1000 135.23898102950378\n",
      "Adagrad tanh MSE\n",
      "100 302.5774310179084\n",
      "200 301.15947861330756\n",
      "300 300.37995069168636\n",
      "400 299.57378040612497\n",
      "500 298.59924174280644\n",
      "600 297.73150025021573\n",
      "700 297.16237236083083\n",
      "800 296.7648997450622\n",
      "900 296.4424440378126\n",
      "1000 296.15072662723566\n",
      "RMSProp sigmoid MSE\n",
      "RMSProp relu MSE\n",
      "RMSProp tanh MSE\n",
      "Adam sigmoid MSE\n",
      "100 289.3719369587153\n",
      "200 278.90269510110636\n",
      "300 276.92004266167885\n",
      "400 276.75562518654584\n",
      "500 276.6951358373201\n",
      "600 276.66353233577905\n",
      "700 276.64429833673506\n",
      "800 276.63148596793496\n",
      "900 276.6224150973181\n",
      "1000 276.61570234040687\n",
      "Adam relu MSE\n",
      "100 61.11154751691371\n",
      "200 21.1464208046586\n",
      "300 12.727149654150764\n",
      "400 9.7508971163268\n",
      "500 8.539750546028458\n",
      "600 7.773485582002711\n",
      "700 7.089278723018802\n",
      "800 6.531346238204375\n",
      "900 6.081761796654079\n",
      "1000 5.763122064022181\n",
      "Adam tanh MSE\n",
      "100 288.58931297766827\n",
      "200 282.1889330967772\n",
      "300 281.01162273411103\n",
      "400 280.74007441176246\n",
      "500 280.6048540941685\n",
      "600 280.51055069926724\n",
      "700 280.4194974355781\n",
      "800 279.80062467147985\n",
      "900 278.57660375695303\n",
      "1000 278.579578772265\n"
     ]
    }
   ],
   "source": [
    "optims=['SGD','SGDNesterov','Adagrad','RMSProp','Adam']\n",
    "activs=['sigmoid','relu','tanh']\n",
    "losses=['MSE']#,'BCELoss','CE']\n",
    "fout = open(\"results.csv\",'w')\n",
    "fout.write(\"iter, optim, activ, loss, funVal \\n\")\n",
    "for optim in optims:\n",
    "    nesterov=False\n",
    "    if optim=='SGDNesterov': nesterov=True\n",
    "    for activ in activs:\n",
    "        for loss in losses:\n",
    "            print(optim, activ, loss)\n",
    "            auto_mpg_model = NeuralNetwork(Xtrain.shape[1], ytrain.shape[1], 64, [activ, activ], loss, optim)\n",
    "            funVals, ypred = auto_mpg_model.train(Xtrain, ytrain, batch_size=100, iterations=1000, alpha=1e-03,momentum_param=0.9, nesterov=nesterov)\n",
    "            auto_mpg_model.reset_weights()\n",
    "            i=0\n",
    "            for val in funVals:\n",
    "                fout.write(str(i)+','+optim+','+activ+','+loss+','+str(val)+'\\n')\n",
    "                i+=1\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
